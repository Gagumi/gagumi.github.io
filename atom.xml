<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://gagumi.github.io</id>
    <title>Gagumi&apos;s blog</title>
    <updated>2023-05-28T11:43:45.435Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://gagumi.github.io"/>
    <link rel="self" href="https://gagumi.github.io/atom.xml"/>
    <subtitle>â€œEfficiency is a clever lazinessâ€&lt;/br&gt;&lt;/br&gt;
ä½ å¥½ï¼Hiï¼ã“ã‚“ã«ã¡ã¯ï¼Bonjourï¼GrÃ¼ÃŸ Gottï¼&lt;/br&gt;&lt;/br&gt;
ğŸ‘‹ Welcome to my site. I am a developer, creator, and designer. My blog documents my creative process, shares my experiences, and explores various technologies</subtitle>
    <logo>https://gagumi.github.io/images/avatar.png</logo>
    <icon>https://gagumi.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Gagumi&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[æœ‰å…³åŠ¨æ¼«ç½‘ç«™èˆ†æƒ…åˆ†æDatalakeçš„å®ç°]]></title>
        <id>https://gagumi.github.io/post/you-guan-dong-man-wang-zhan-yu-qing-fen-xi-datalake-de-shi-xian/</id>
        <link href="https://gagumi.github.io/post/you-guan-dong-man-wang-zhan-yu-qing-fen-xi-datalake-de-shi-xian/">
        </link>
        <updated>2023-05-27T17:39:48.000Z</updated>
        <summary type="html"><![CDATA[<p style="font-size:20px;">ä¹‹å‰çš„åšå®¢å·²ç»å¯¹APIæœ‰äº†å……åˆ†çš„äº†è§£ï¼Œç”±äºå…¶å±€é™æ€§ï¼Œé™¤äº†æ‰‹åŠ¨çˆ¬å–ä¸‹æ¥çš„06-23å¹´åŠ¨ç”»çš„è¯„è®ºæ•°æ®ä»¥å¤–ã€‚æœ¬ç¯‡æ‰€æœ‰çš„å®ç°éƒ½æ˜¯åŸºäºå®æ—¶top50åŠ¨æ¼«çš„ç±»å‹åˆ†æå’Œè¯„è®ºåˆ†æã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
]]></summary>
        <content type="html"><![CDATA[<p style="font-size:20px;">ä¹‹å‰çš„åšå®¢å·²ç»å¯¹APIæœ‰äº†å……åˆ†çš„äº†è§£ï¼Œç”±äºå…¶å±€é™æ€§ï¼Œé™¤äº†æ‰‹åŠ¨çˆ¬å–ä¸‹æ¥çš„06-23å¹´åŠ¨ç”»çš„è¯„è®ºæ•°æ®ä»¥å¤–ã€‚æœ¬ç¯‡æ‰€æœ‰çš„å®ç°éƒ½æ˜¯åŸºäºå®æ—¶top50åŠ¨æ¼«çš„ç±»å‹åˆ†æå’Œè¯„è®ºåˆ†æã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
<!-- more -->
<h3 id="è®­ç»ƒæ•°æ®çš„é¢„å¤„ç†ä¸æ¨¡å‹çš„è®­ç»ƒ">è®­ç»ƒæ•°æ®çš„é¢„å¤„ç†ä¸æ¨¡å‹çš„è®­ç»ƒ</h3>
<p>å‰ç¯‡æ‰€è·å¾—çš„è¯„è®ºä¸æ ‡è®°æ•°æ®ï¼Œåœ¨è¿™é‡Œçš„æ€è·¯æ˜¯è¿›è¡Œæœºå™¨å­¦ä¹ åˆ†ç±»å™¨çš„è®­ç»ƒã€‚å¸¸è§çš„æ–¹æ³•æœ‰ï¼ˆæ”¯æŒå‘é‡æœºSVMï¼Œå†³ç­–æ ‘ï¼Œæœ´ç´ è´å¶æ–¯ç­‰ï¼‰å…¶ä¸­æ”¯æŒå‘é‡æœºå®Œæˆçš„æ˜¯äºŒåˆ†ä»»åŠ¡ï¼Œé‰´äºæœ¬æ¬¡æ¨¡å‹éœ€è¦åˆ†ç±»å‡ºï¼ˆrecommendï¼Œnot recommendå’Œmixed fillingï¼‰æ‰€ä»¥é€‰æ‹©æœ´ç´ è´å¶æ–¯æˆ–æ˜¯å†³ç­–æ ‘ã€‚ç”±äºæœ´ç´ è´å¶æ–¯çš„ç»“æœè¿‡äºç¦»è°±ï¼Œè¿™é‡Œé€‰ç”¨å†³ç­–æ ‘ã€‚</p>
<p>é¢„å¤„ç†æ–¹é¢ï¼Œè¿™é‡Œçš„æ€è·¯æ˜¯ä½¿ç”¨NLTKå®˜æ–¹çš„åœç”¨è¯å’Œè¯å½¢è¿˜åŸå™¨ã€‚ç„¶åè‡ªå®šä¹‰ä¸€ä¸ªæ–‡æœ¬æ¸…æ´—å‡½æ•°æ¥å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œæ ‡ç‚¹ç¬¦å·å’Œæ•°å­—ã€‚</p>
<p>ç‰¹å¾è¡¨ç¤ºæ–¹é¢ï¼Œæœ‰ä¸‰ç§å¸¸è§çš„ç‰¹å¾è¡¨ç¤ºæ–¹æ³•ï¼ˆè¯è¢‹æ¨¡å‹ï¼ŒTF-IDFï¼Œword2vecï¼‰ã€‚ç”±äºå“¥ä»¬å¯¹NLPç¡®å®ä¸å¤Ÿäº†è§£ï¼Œè¿™é‡Œä½¿ç”¨æš´åŠ›çš„æ–¹æ³•ï¼Œä½¿ç”¨ä¸‰ä¸ªç‰¹å¾è¡¨ç¤ºéƒ½ä½¿ç”¨ç„¶åå–æœ€ä¼˜çš„æš´åŠ›æ–¹æ³•ã€‚</p>
<p>ä»¥ä¸‹æ˜¯è®­ç»ƒä»£ç ï¼š</p>
<pre><code class="language-python">import re
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split, cross_val_score
from gensim.models import Word2Vec
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import joblib
from tqdm import tqdm

# ä¸‹è½½NLTKçš„åœç”¨è¯å’Œè¯å½¢è¿˜åŸå™¨æ‰€éœ€çš„æ•°æ®
nltk.download('stopwords')
nltk.download('wordnet')

# åˆå§‹åŒ–è¯å½¢è¿˜åŸå™¨å’Œåœç”¨è¯é›†åˆ
lemmatizer = WordNetLemmatizer()
stopwords = list(stopwords.words('english'))


# è‡ªå®šä¹‰æ–‡æœ¬æ¸…æ´—å‡½æ•°
def clean_text(text):
    # å»é™¤ç‰¹æ®Šå­—ç¬¦ã€æ ‡ç‚¹ç¬¦å·å’Œæ•°å­—
    text = re.sub(r&quot;[^\w\s]&quot;, &quot;&quot;, text)
    text = re.sub(r&quot;\d+&quot;, &quot;&quot;, text)
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower()
    return text

# è¯»å–è®­ç»ƒæ•°æ®é›†
df = pd.read_csv(&quot;standard_dataset.csv&quot;)

# æ¸…æ´—æ–‡æœ¬æ•°æ®
df[&quot;Comment&quot;] = df[&quot;Comment&quot;].apply(clean_text)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X = df[&quot;Comment&quot;]
y = df[&quot;Recommendation&quot;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ç‰¹å¾è¡¨ç¤ºæ–¹æ³•1: è¯è¢‹æ¨¡å‹
count_vectorizer = CountVectorizer(stop_words=stopwords)
X_count = count_vectorizer.fit_transform(X)

# ä¿å­˜CountVectorizer
count_vectorizer_filename = &quot;count_vectorizer.pkl&quot;
joblib.dump(count_vectorizer, count_vectorizer_filename)
print(f&quot;CountVectorizer saved as {count_vectorizer_filename}&quot;)

# ç‰¹å¾è¡¨ç¤ºæ–¹æ³•2: TF-IDF
tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)
X_tfidf = tfidf_vectorizer.fit_transform(X)

# ä¿å­˜TfidfVectorizer
tfidf_vectorizer_filename = &quot;tfidf_vectorizer.pkl&quot;
joblib.dump(tfidf_vectorizer, tfidf_vectorizer_filename)
print(f&quot;TfidfVectorizer saved as {tfidf_vectorizer_filename}&quot;)

# ç‰¹å¾è¡¨ç¤ºæ–¹æ³•3: Word2Vec
sentences = [nltk.word_tokenize(text) for text in X]
word2vec_model = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)
X_word2vec = [word2vec_model.wv[nltk.word_tokenize(text)].mean(axis=0) for text in X]

# ä¿å­˜Word2Vecæ¨¡å‹
word2vec_model_filename = &quot;word2vec_model.pkl&quot;
word2vec_model.save(word2vec_model_filename)
print(f&quot;Word2Vec model saved as {word2vec_model_filename}&quot;)

# æ„å»ºå†³ç­–æ ‘æ¨¡å‹
decision_tree = DecisionTreeClassifier()

# äº¤å‰éªŒè¯æ¯”è¾ƒä¸åŒç‰¹å¾è¡¨ç¤ºæ–¹æ³•çš„æ€§èƒ½
methods = [(&quot;CountVectorizer&quot;, X_count), (&quot;TF-IDF&quot;, X_tfidf), (&quot;Word2Vec&quot;, X_word2vec)]
best_method = None
best_score = 0.0

for method_name, X_method in tqdm(methods):
    scores = cross_val_score(decision_tree, X_method, y, cv=5)
    avg_score = scores.mean()
    print(f&quot;{method_name} - Average Score: {avg_score}&quot;)
    
    if avg_score &gt; best_score:
        best_score = avg_score
        best_method = method_name

print(f&quot;\nBest Method: {best_method}&quot;)

# ä½¿ç”¨æœ€ä¼˜ç‰¹å¾è¡¨ç¤ºæ–¹æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•
if best_method == &quot;CountVectorizer&quot;:
    X_train_best = count_vectorizer.transform(X_train)
    X_test_best = count_vectorizer.transform(X_test)
elif best_method == &quot;TF-IDF&quot;:
    X_train_best = tfidf_vectorizer.transform(X_train)
    X_test_best = tfidf_vectorizer.transform(X_test)
elif best_method == &quot;Word2Vec&quot;:
    X_train_best = [word2vec_model.wv[nltk.word_tokenize(text)].mean(axis=0) for text in X_train]
    X_test_best = [word2vec_model.wv[nltk.word_tokenize(text)].mean(axis=0) for text in X_test]

decision_tree.fit(X_train_best, y_train)
y_pred = decision_tree.predict(X_test_best)

# è¾“å‡ºæ¨¡å‹è¯„ä¼°å‚æ•°
classification_report = classification_report(y_test, y_pred)
print(f&quot;\nClassification Report ({best_method}):&quot;)
print(classification_report)

# ä¿å­˜å†³ç­–æ ‘æ¨¡å‹
decision_tree_filename = &quot;decision_tree_model.pkl&quot;
joblib.dump(decision_tree, decision_tree_filename)
print(f&quot;Decision tree model saved as {decision_tree_filename}&quot;)
</code></pre>
<p>è¿™é‡Œåšå‡ºè§£é‡Šï¼šä¸ºä»€ä¹ˆæ¨¡å‹çš„è®­ç»ƒè¿™ä¸€æ­¥ä¸ä¹Ÿåœ¨sparkä¸Šè¿›è¡Œï¼Ÿ</p>
<p>å› ä¸ºä½¿ç”¨çš„google dataproc sparkå¹³å°ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆè¯»å–ä¸äº†å“¥ä»¬åœ¨googleå‚¨å­˜æ¡¶é‡Œä¸Šä¼ çš„è®­ç»ƒé›†ï¼Œå¦å¤–ç”±äºä½¿ç”¨çš„æ˜¯è¯•ç”¨çš„ä¸ç‰ˆï¼Œè²Œä¼¼cpuèµ„æºä¹Ÿä¸å¤Ÿè®­ç»ƒä¸€ä¸ªå†³ç­–æ ‘æ¨¡å‹ã€‚æ•…è€Œå†³ç­–æ ‘æ¨¡å‹çš„è®­ç»ƒåœ¨æœ¬åœ°å®Œæˆã€‚</p>
<p>å®Œæˆè®­ç»ƒä¹‹åå‡†å¤‡å·¥ä½œå®Œæˆï¼Œæ­£å¼å¼€å§‹datalakeçš„æ­å»ºã€‚</p>
<h3 id="æ€è·¯æ€»ç»“">æ€è·¯æ€»ç»“</h3>
<p>é€šè¿‡airflow DAGæ§åˆ¶ä¸‰ä¸ªä»»åŠ¡ï¼š</p>
<p>1.è·å–myanimelistæ’è¡Œå‰äº”ååŠ¨æ¼«çš„åŸºæœ¬ä¿¡æ¯ï¼ˆæœ€é‡è¦çš„æ˜¯IDï¼Œç±»å‹ï¼‰ï¼Œä¼ å…¥kafkaçš„topicï¼š'all_anime_tops'</p>
<p>2.ä½¿ç”¨sparkåšæ•°æ®å¤„ç†ï¼ˆä½œä¸ºkafka ç¬¬ä¸€æ­¥topicçš„æ¶ˆè´¹è€…ï¼‰ï¼Œè·å¾—è¿™äº›åŠ¨æ¼«çš„æ‰€æœ‰ç±»å‹æ ‡ç­¾å°è£…åœ¨jsonæ–‡ä»¶ä¸­ï¼Œä¼ å…¥åˆ°kafkaçš„topicï¼š'all_anime_genres_counts'</p>
<p>3.è·å–kitsuæ’è¡Œå‰äº”ååŠ¨æ¼«çš„è¯„è®ºä¿¡æ¯ï¼ˆæœ€é‡è¦çš„æ˜¯IDå’Œè¯„è®ºï¼ˆè¯„è®ºå§‹ç»ˆå–æœ€æ–°å‰äº”æ¡ï¼‰ï¼‰è½½å…¥æœ¬åœ°é¢„è®­ç»ƒå¥½çš„å†³ç­–æ ‘æ¨¡å‹ï¼Œè·å¾—è¿™äº›è¯„è®ºçš„è¯­ä¹‰å°è£…æˆjsonï¼Œä¼ å…¥åˆ°kafkaçš„topicï¼š'prediction_topics'</p>
<p>4.elasticæ¶ˆè´¹2 3 æ­¥çš„kafka topicï¼Œä½¿ç”¨kibanaåšå®æ—¶å¯è§†åŒ–ã€‚</p>
<p>æ¥ä¸‹é‡Œå¼€å§‹å®è·µã€‚</p>
<h3 id="å¹³å°çš„å‡†å¤‡ä¸æ³¨å†Œ">å¹³å°çš„å‡†å¤‡ä¸æ³¨å†Œ</h3>
<p>æœ¬æ¬¡é¡¹ç›®æ‰€ä½¿ç”¨çš„æ‰€æœ‰å·¥å…·ï¼ˆairflowï¼Œsparkï¼Œkafkaï¼Œelkï¼‰å‡æ˜¯äº‘ç«¯å¹³å°ï¼Œä½¿ç”¨API keyè¿›è¡Œè¿æ¥ã€‚æ‰€æœ‰å¹³å°å‡æœ‰å…è´¹ç™½å«–çš„è¯´æ³•ã€‚</p>
<p>åˆ†åˆ«å¯¹åº” google cloudçš„cloud composerï¼ˆairflowï¼‰ï¼Œdataproc é›†ç¾¤ï¼ˆsparkï¼‰ï¼›confluent cloudï¼ˆkafkaï¼‰ï¼›elkï¼ˆElasticsearchã€Logstash å’Œ Kibanaï¼‰</p>
<p>å¹³å°çš„æ³¨å†Œéƒ½æ¯”è¾ƒç®€å•ï¼Œè¿™é‡Œä¸å¤šèµ˜è¿°ã€‚</p>
<p>è¿›å…¥googleå¹³å°åï¼Œè®°å¾—æ–°å»ºä¸€ä¸ªé¡¹ç›®ã€‚è¿™é‡Œæˆ‘çš„é¡¹ç›®å¦‚ä¸‹ï¼š</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528113408.png" alt="" loading="lazy"></figure>
<h3 id="éœ€è¦çš„api-keyè·å–ä»¥åŠkafka-topicè¿æ¥å™¨çš„å»ºç«‹">éœ€è¦çš„API keyè·å–ä»¥åŠkafka topicï¼Œè¿æ¥å™¨çš„å»ºç«‹</h3>
<p>ç™»å½•ç½‘ç«™https://confluent.cloud/loginï¼Œæ³¨å†Œè·å¾—è¯•ç”¨èµ„æ ¼ã€‚</p>
<p>åˆ›å»ºä¸€ä¸ªæ–°çš„ç¯å¢ƒå’Œclusterï¼ˆä¸€æ­¥ä¸€æ­¥è·Ÿç€å¼•å¯¼èµ°å³å¯ï¼‰</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528120136.png" alt="" loading="lazy"></figure>
<p>è¿›å…¥è¿™ä¸ªé›†ç¾¤ï¼Œç‚¹å‡»å·¦ä¾§API keyï¼Œå³ä¸Šè§’addä¸€ä¸ªæ–°keyï¼Œä¸‹è½½ä¸‹æ¥ä¿å­˜å¥½ã€‚</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528120309.png" alt="" loading="lazy"></figure>
<p>æ¥ä¸‹æ¥ç‚¹å‡»topicsï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¹‹å‰æ€è·¯é‡Œæåˆ°çš„ä¸‰ä¸ªtopicã€‚</p>
<p>å»ºç«‹ä¹‹å‰ï¼Œæ ¹æ®æˆ‘ä»¬å®éªŒè¯¾æ‰€å­¦ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå»ºç«‹elkç›¸å…³ç‰©ä»¶ã€‚ä»¥æ¶ˆè´¹è¿™äº›topicåšåˆ°å¯è§†åŒ–ã€‚</p>
<p>å»ºç«‹é›†ç¾¤ä¹‹åï¼Œæˆ‘ä»¬ä¼šè¢«è¦æ±‚ä¸‹è½½api keyå’Œå¯†ç ï¼Œä¿å­˜å¥½ã€‚</p>
<p>ç„¶åç‚¹å‡»å·¦ä¾§ï¼š<br>
<img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528120803.png" alt="" loading="lazy"></p>
<p>è¿›å…¥deplomentï¼Œåœ¨è¿™é‡Œå•å‡»å¤åˆ¶è·å¾—elkçš„é“¾æ¥ï¼ˆhttps://biganime.es.us-central1.gcp.cloud.es.ioï¼‰</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528120914.png" alt="" loading="lazy"></figure>
<p>æ¥ä¸‹æ¥å›åˆ°kafkaæˆ‘ä»¬å¯ä»¥åˆ›å»ºtopicäº†</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528121519.png" alt="" loading="lazy"></figure>
<p>è¾“å…¥topicåå­—ï¼Œæˆ‘è¿™é‡Œä¾æ¬¡åˆ›å»ºäº†æ€è·¯é‡Œçš„ä¸‰ä¸ªtopicã€‚ï¼ˆ'all_anime_tops'ï¼Œ'all_anime_genres_counts'ï¼Œprediction_topicsï¼‰</p>
<p>æ¥ä¸‹æ¥åˆ›å»ºè¿æ¥å™¨ï¼ˆç±»å‹é€‰elkï¼‰ä¸elké“¾æ¥ä»¥å®ç°å¯è§†åŒ–ï¼š</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528124818.png" alt="" loading="lazy"></figure>
<p>æŒ‰ç…§ä¸Šå›¾åˆ›å»ºï¼Œæ³¨æ„ignoreæ‰keyå’Œschemaï¼Œä¸€èˆ¬æ¥è¯´æ˜¯ä¸å»ºè®®è¿™æ ·çš„ï¼Œä½†æ˜¯ä¸å¿½ç•¥ä¼šäº§ç”Ÿæˆ‘æ— æ³•è§£å†³çš„é—®é¢˜ã€‚</p>
<h3 id="airflowç›¸å…³">airflowç›¸å…³</h3>
<p>åœ¨åˆ›å»ºcomposerï¼ˆhttps://cloud.google.com/composerï¼‰çš„æ—¶å€™ï¼Œå¯ä»¥è¿›è¡Œé€‰æ‹©:</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528113449.png" alt="" loading="lazy"></figure>
<p>composer2æˆ‘å§‹ç»ˆæ— æ³•æˆåŠŸåˆ›å»ºã€‚æ•…é€‰æ‹©çš„æ˜¯composer1.</p>
<p>åˆ›å»ºä¹‹åè¿›å…¥ç•Œé¢ï¼š</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528113634.png" alt="" loading="lazy"></figure>
<p>é¦–å…ˆæˆ‘ä»¬éœ€è¦å®‰è£…ä¸€ä¸ªé¢å¤–çš„åŒ…ï¼Œæ¥ä¿è¯airflowå’Œkafkaçš„é€šè®¯ï¼Œç‚¹å‡»pypiè½¯ä»¶åŒ…ï¼Œå®‰è£…confluent-kafkaã€‚</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528113840.png" alt="" loading="lazy"></figure>
<p>æ¥ä¸‹æ¥æ‰“å¼€DAGæ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬çš„DAGæ–‡ä»¶å°±éœ€è¦æ”¾å…¥å…¶ä¸­ã€‚</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528114132.png" alt="" loading="lazy"></figure>
<p>è¿™é‡Œæˆ‘åœ¨DAGç›®å½•çš„ä¸Šä¸€çº§ç›®å½•æ–°å»ºäº†ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œåœ¨é‡Œé¢å­˜æ”¾äº†æ‰€æœ‰ä¼šç”¨çš„ä¸œè¥¿ï¼ˆåŒ…æ‹¬sparkè¿è¡Œæ‰€éœ€çš„jaråŒ…ï¼Œsparkå®‰è£…åçš„åˆå§‹åŒ–shå‘½ä»¤ï¼Œsparké“¾æ¥kafkaæ‰€éœ€è¦çš„confå‡­è¯ï¼Œsparkä»»åŠ¡pyæ–‡ä»¶ï¼Œé¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰ï¼Œå°†è¿™ä¸ªgså‚¨å­˜æ¡¶å½“ä½œäº†ä¸€ä¸ªç®€æ˜“äº‘ç›˜ä½¿ç”¨ã€‚éœ€è¦è°ƒç”¨å…¶ä¸­æ•°æ®æ—¶ï¼Œå°±å¯ä»¥é€šè¿‡ï¼š</p>
<pre><code class="language-html">gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/file
</code></pre>
<p>è°ƒç”¨ã€‚</p>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528115648.png" alt="" loading="lazy"></figure>
<h3 id="sparkç›¸å…³">sparkç›¸å…³</h3>
<p>è¿™ä¸€éƒ¨åˆ†æ—¶å¡ä½æˆ‘æœ€ä¹…çš„éƒ¨åˆ†ï¼Œgoogle dataprocçš„ç¯å¢ƒé—®é¢˜æœ‰ç‚¹å¤šã€‚</p>
<p>é¦–å…ˆå¯¹äºè¯¥é›†ç¾¤çš„æ­å»ºï¼Œæˆ‘ä½¿ç”¨äº†å‘½ä»¤è¡Œçš„æ­å»ºæ–¹å¼ã€‚</p>
<p>å½“æˆ‘ä»¬å¯ç”¨äº†google dataprocåï¼Œæˆ‘ä»¬æ¥åˆ°å…¶æ§åˆ¶å°ç•Œé¢ï¼š</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528115550.png" alt="" loading="lazy"></figure>
<p>å•å‡»è¿™é‡Œå³å¯è¿›å…¥æ§åˆ¶å°ã€‚ä¸è¿‡åœ¨æ­¤ä¹‹å‰æˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›å‡†å¤‡ã€‚</p>
<p>é¦–å…ˆå»ºè®®ä½¿ç”¨çš„æ—¶20å¹´çš„ubuntuç¯å¢ƒï¼Œè™½è¯´ä¸æ˜¯æœ€æ–°çš„ï¼Œä½†æ˜¯ä¸ªäººè®¤ä¸ºæ¯”è¾ƒç¨³å®šã€‚</p>
<p>ä½¿ç”¨vscodeç­‰IDEæˆ‘ä»¬æ–°å»ºä¸€ä¸ªæ–‡ä»¶jaas.confï¼ˆkafkaè¿æ¥å‡­è¯ï¼‰ï¼š</p>
<pre><code class="language-java">KafkaClient {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username=&quot;4GLFTYVSO5V7MJ6B&quot;
  password=&quot;71JNm1voEHT/NBq8BtAVVLfs8nhmnfcyxHJFCLZLwFPjOfJ9rJ0On4DNnMfun97c&quot;;
};
</code></pre>
<p>è¿™é‡Œå¡«ä¸Šä½ çš„kafka API keyã€‚</p>
<p>å†åˆ›å»ºä¸€ä¸ªshï¼ˆcopy_jaas.shï¼‰æ¥æ§åˆ¶dataproc sparké›†ç¾¤åˆ›å»ºæ—¶éœ€è¦å®Œæˆçš„å·¥ä½œï¼ˆå¯¼å…¥kafkaæ”¯æŒåŒ…ï¼Œå¯¼å…¥é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç§»åŠ¨kafkaé“¾æ¥å‡­è¯ï¼‰</p>
<pre><code class="language-sh">#!/bin/bash

# åˆ›å»ºæ¨¡å‹å­˜å‚¨ç›®å½•
mkdir -p /home/model/

# ä¸‹è½½æ¨¡å‹åˆ°æ¨¡å‹å­˜å‚¨ç›®å½•
gsutil cp gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/decision_tree_model.pkl /home/model/
gsutil cp gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/count_vectorizer.pkl /home/model/

# å®‰è£…åº“
/opt/conda/default/bin/pip install langdetect
/opt/conda/default/bin/pip install confluent_kafka
/opt/conda/default/bin/pip install requests
/opt/conda/default/bin/pip install joblib
/opt/conda/default/bin/pip install scikit-learn

# ä¸‹è½½ jaas.conf æ–‡ä»¶
gsutil cp gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/jaas.conf /etc/
</code></pre>
<p>æ¥ä¸‹æ¥å›åˆ°dataprocé›†ç¾¤ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ï¼š</p>
<pre><code class="language-shell">gcloud dataproc clusters create cluster-biganime     --region us-west4     --zone us-west4-b     --single-node     --master-machine-type n2-standard-4     --master-boot-disk-size 500     --image-version 1.5-ubuntu18     --project biganime     --initialization-actions gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/copy_jaas.sh
</code></pre>
<p>å›è½¦åˆ›å»ºä¸€ä¸ªæ–°çš„é›†ç¾¤ã€‚</p>
<h3 id="dagå†…å®¹">DAGå†…å®¹</h3>
<p>ä»¥ä¸‹æ—¶DAGæ–‡ä»¶airflow_top50_test.pyçš„å†…å®¹ï¼š</p>
<pre><code class="language-python">from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.contrib.operators.dataproc_operator import DataProcPySparkOperator
from datetime import datetime, timedelta
from requests.auth import HTTPBasicAuth
import requests
import json
import time
from confluent_kafka import SerializingProducer
from confluent_kafka.serialization import StringSerializer

def send_anime_top_to_kafka():
    # æ¸…ç©º Elasticsearch ç´¢å¼•
    indices_to_delete = [&quot;all_anime_tops&quot;, &quot;all_anime_genres_counts&quot;]

    for index in indices_to_delete:
        response = requests.delete(
            f'https://biganime.es.us-central1.gcp.cloud.es.io/{index}',
            auth=HTTPBasicAuth('elastic', '8wt3nRsnx1IufleEMs8CIOYL')
        )
        if response.status_code == 200:
            print(f&quot;Index {index} has been deleted successfully&quot;)
        elif response.status_code == 404:
            print(f&quot;Index {index} did not exist&quot;)
        else:
            print(f&quot;Error occurred while deleting index {index}&quot;)

    producer_conf = {
        'bootstrap.servers': 'pkc-6ojv2.us-west4.gcp.confluent.cloud:9092',
        'security.protocol': 'SASL_SSL',
        'sasl.mechanisms': 'PLAIN',
        'sasl.username': '4GLFTYVSO5V7MJ6B',
        'sasl.password': '71JNm1voEHT/NBq8BtAVVLfs8nhmnfcyxHJFCLZLwFPjOfJ9rJ0On4DNnMfun97c',
        'key.serializer': StringSerializer('utf_8'),
        'value.serializer': StringSerializer('utf_8')
    }
    producer = SerializingProducer(producer_conf)

    for page in [1, 2]:
        response = requests.get(f&quot;https://api.jikan.moe/v4/top/anime?page={page}&quot;)
        top_anime = response.json()

        for anime in top_anime['data']:
            response = requests.get(f&quot;https://api.jikan.moe/v4/anime/{anime['mal_id']}&quot;)
            anime_detail = response.json()

            message_key = anime_detail['data']['title']
            print(message_key)
            message_value = {
                &quot;title&quot;: message_key,
                &quot;genres&quot;: [genre['name'] for genre in anime_detail['data']['genres']],
                &quot;timestamp&quot;: int(time.time())  # æ·»åŠ å½“å‰æ—¶é—´æˆ³
            }
            message_value = json.dumps(message_value)

            producer.produce(topic='all_anime_tops', key=message_key, value=message_value)

            time.sleep(1)

    producer.flush()

# åˆ›å»º Airflow DAG
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 5, 24),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'send_anime_top_to_kafka',
    default_args=default_args,
    description='A simple DAG to send anime top to Kafka',
    #schedule_interval='0 7,14 * * *',  # Run at 7AM and 2PM every day
    schedule_interval=None,  # No schedule, only run when manually triggered
    catchup=False
)

t1 = PythonOperator(
    task_id='send_anime_top_to_kafka',
    python_callable=send_anime_top_to_kafka,
    dag=dag,
)

pyspark_job1 = DataProcPySparkOperator(
    task_id='run_pyspark_on_anime_top50_pyspark',
    main='gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/anime_top50_pyspark.py',
    dataproc_properties={
        'spark.executor.extraJavaOptions': '-Djava.security.auth.login.config=/etc/jaas.conf',
        'spark.driver.extraJavaOptions': '-Djava.security.auth.login.config=/etc/jaas.conf'
    },
    dataproc_jars=[
        'gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/spark-sql-kafka-0-10_2.12-2.4.8.jar',
        'gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/kafka-clients-0.10.2.2.jar'
    ],
    cluster_name='cluster-biganime',
    region='us-west4',
    project_id='biganime',
    dag=dag
)

pyspark_job2 = DataProcPySparkOperator(
    task_id='run_pyspark_on_anime_sentiment_prediction',
    main='gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/anime_sentiment_prediction.py',
    dataproc_properties={
        'spark.executor.extraJavaOptions': '-Djava.security.auth.login.config=/etc/jaas.conf',
        'spark.driver.extraJavaOptions': '-Djava.security.auth.login.config=/etc/jaas.conf'
    },
    dataproc_jars=[
        'gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/spark-sql-kafka-0-10_2.12-2.4.8.jar',
        'gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/kafka-clients-0.10.2.2.jar'
    ],
    cluster_name='cluster-biganime',
    region='us-west4',
    project_id='biganime',
    dag=dag
)

t1 &gt;&gt; [pyspark_job1, pyspark_job2]  # å°† PySpark ä»»åŠ¡æ·»åŠ åˆ° DAG ä¸­ï¼Œå¹¶è¡Œæ‰§è¡Œ

</code></pre>
<p>å…¶ä¸­ï¼Œkafkaçš„bootstrap.serverså¯ä»¥åœ¨å¦‚ä¸‹åœ°æ–¹è·å–ï¼š</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528130615.png" alt="" loading="lazy"></figure>
<p>å¦å¤–ï¼Œä¸¤ä¸ªpyspark_jobå¯åŠ¨æ—¶æ‰€éœ€è¦çš„jaråŒ…æ˜¯éœ€è¦å¯¹åº”sparkç‰ˆæœ¬è‡ªè¡Œä¸‹è½½å¹¶ä¸Šä¼ çš„ã€‚</p>
<pre><code class="language-python">dag = DAG(
    'send_anime_top_to_kafka',
    default_args=default_args,
    description='A simple DAG to send anime top to Kafka',
    #schedule_interval='0 7,14 * * *',  # Run at 7AM and 2PM every day
    schedule_interval=None,  # No schedule, only run when manually triggered
    catchup=False
)
</code></pre>
<p>è¿™é‡Œæˆ‘ä¹Ÿè®¾ç½®çš„æ˜¯DAGè§¦å‘ä¸€æ¬¡æ‰§è¡Œä¸€æ¬¡ï¼Œè€Œä¸æ˜¯çœŸæ­£æŒ‰ç…§ä¸€å¤©å‘é€ä¸¤æ¬¡ï¼ˆæ–¹ä¾¿æµ‹è¯•ï¼‰</p>
<p>æ¥ä¸‹æ¥æ˜¯åœ¨sparkä¸Šè¿è¡Œçš„ä¸¤ä¸ªpy</p>
<p>anime_top50_pyspark.pyï¼ˆå®Œæˆäº†ä»kafkaè¯»å–æ•°æ®è¿›è¡Œå¤„ç†åå†ä¼ å›æ–°çš„topicçš„è¿‡ç¨‹ï¼‰</p>
<pre><code class="language-python">from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split, from_json, col, trim
from pyspark.sql.types import StructType, StructField, StringType, LongType  # æ·»åŠ è¿™è¡Œå¯¼å…¥è¯­å¥


spark = SparkSession.builder.appName(&quot;KafkaToKafka&quot;).getOrCreate()

# Define the schema of the input data
schema = StructType([
    StructField(&quot;title&quot;, StringType(), True),
    StructField(&quot;genres&quot;, StringType(), True),
    StructField(&quot;timestamp&quot;, LongType(), True)
])

# ä» Kafka è¯»å–æ•°æ®
df = spark \
  .readStream \
  .format(&quot;kafka&quot;) \
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;pkc-6ojv2.us-west4.gcp.confluent.cloud:9092&quot;) \
  .option(&quot;subscribe&quot;, &quot;all_anime_tops&quot;) \
  .option(&quot;kafka.security.protocol&quot;, &quot;SASL_SSL&quot;) \
  .option(&quot;kafka.sasl.mechanism&quot;, &quot;PLAIN&quot;) \
  .option(&quot;kafka.sasl.username&quot;, &quot;4GLFTYVSO5V7MJ6B&quot;) \
  .option(&quot;failOnDataLoss&quot;, False) \
  .option(&quot;kafka.sasl.password&quot;, &quot;71JNm1voEHT/NBq8BtAVVLfs8nhmnfcyxHJFCLZLwFPjOfJ9rJ0On4DNnMfun97c&quot;) \
  .load()


# Extract the value of the messages and parse the JSON
df = df.select(from_json(col(&quot;value&quot;).cast(&quot;string&quot;), schema).alias(&quot;data&quot;))

# å¤„ç† genresï¼Œå»é™¤ä¸¤ç«¯çš„å¼•å·å’Œç©ºæ ¼
genres_df = df.select(explode(split(df.data.genres, &quot;,&quot;)).alias(&quot;genre&quot;))
genres_df = genres_df.withColumn(&quot;genre&quot;, trim(genres_df.genre))

# å°†ç»“æœè½¬ä¸º JSON æ ¼å¼ï¼Œå…¶ä¸­æ¯æ¡è®°å½•åŒ…å« genre
genres_df_json = genres_df.selectExpr(&quot;to_json(struct(*)) AS value&quot;)

# å°†ç»“æœå†™å› Kafka
query = genres_df_json \
  .writeStream \
  .outputMode(&quot;update&quot;) \
  .format(&quot;kafka&quot;) \
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;pkc-6ojv2.us-west4.gcp.confluent.cloud:9092&quot;) \
  .option(&quot;topic&quot;, &quot;all_anime_genres_counts&quot;) \
  .option(&quot;kafka.security.protocol&quot;, &quot;SASL_SSL&quot;) \
  .option(&quot;kafka.sasl.mechanism&quot;, &quot;PLAIN&quot;) \
  .option(&quot;kafka.sasl.username&quot;, &quot;4GLFTYVSO5V7MJ6B&quot;) \
  .option(&quot;kafka.sasl.password&quot;, &quot;71JNm1voEHT/NBq8BtAVVLfs8nhmnfcyxHJFCLZLwFPjOfJ9rJ0On4DNnMfun97c&quot;) \
  .option(&quot;checkpointLocation&quot;, &quot;gs://europe-west1-biganime-1990c8ad-bucket/checkpoints/&quot;) \
  .start() 

query.awaitTermination(1000)

</code></pre>
<p>anime_sentiment_prediction.pyï¼ˆå®Œæˆäº†å®æ—¶ä»kitsuä¸ŠæŠ“å–æ•°æ®å¹¶è¿›è¡Œå†³ç­–æ•°åˆ†æçš„è¿‡ç¨‹ï¼‰</p>
<pre><code class="language-python">from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col
from pyspark.sql.types import StringType
from confluent_kafka import SerializingProducer
from confluent_kafka.serialization import StringSerializer
import requests
import joblib
import re
from datetime import datetime
import json  # Import json module

# å‡½æ•°ï¼šå°†ISO 8601æ ¼å¼çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³
def get_timestamp_from_iso8601(iso8601_str):
    date_time_obj = datetime.strptime(iso8601_str, '%Y-%m-%dT%H:%M:%S.%fZ')
    timestamp = datetime.timestamp(date_time_obj)
    return str(timestamp)

# å‡½æ•°ï¼šæ¸…æ´—æ–‡æœ¬
def clean_text(text):
    text = re.sub(r&quot;[^\w\s]&quot;, &quot;&quot;, text)
    text = re.sub(r&quot;\d+&quot;, &quot;&quot;, text)
    text = text.lower()
    return text

# å‡½æ•°ï¼šé¢„æµ‹æƒ…ç»ª
def predict_sentiment(text):
    text = clean_text(text)
    vectorized_text = count_vectorizer.transform([text]).toarray()
    prediction = decision_tree.predict(vectorized_text)[0]

    word_count = len(text.split())
    if word_count &lt; 10:
        return &quot;0&quot;  # Mixed Feelings
    elif word_count &gt; 20:
        return &quot;-1&quot;  # Not Recommended
    else:
        if prediction == &quot;Recommended&quot;:
            return &quot;1&quot;
        else:
            return &quot;0&quot;  # Mixed Feelings

spark = SparkSession.builder.appName(&quot;AnimeSentimentPrediction&quot;).getOrCreate()

# åŠ è½½å†³ç­–æ ‘æ¨¡å‹å’Œ CountVectorizer
#decision_tree = joblib.load(&quot;gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/decision_tree_model.pkl&quot;)
#count_vectorizer = joblib.load(&quot;gs://europe-west1-biganime-1990c8ad-bucket/biganime_pyspark/count_vectorizer.pkl&quot;)
decision_tree = joblib.load('/home/model/decision_tree_model.pkl')
count_vectorizer = joblib.load('/home/model/count_vectorizer.pkl')

# Kafkaç”Ÿäº§è€…é…ç½®
producer_conf = {
    'bootstrap.servers': 'pkc-6ojv2.us-west4.gcp.confluent.cloud:9092',
    'security.protocol': 'SASL_SSL',
    'sasl.mechanisms': 'PLAIN',
    'sasl.username': '4GLFTYVSO5V7MJ6B',
    'sasl.password': '71JNm1voEHT/NBq8BtAVVLfs8nhmnfcyxHJFCLZLwFPjOfJ9rJ0On4DNnMfun97c',
    'key.serializer': StringSerializer('utf_8'),
    'value.serializer': StringSerializer('utf_8')
}
producer = SerializingProducer(producer_conf)

# Kitsuè¯„è®ºé¢„æµ‹
for i in range(3):
    page_number = i + 1
    url = f&quot;https://kitsu.io/api/edge/anime?sort=-user_count&amp;page[limit]=20&amp;page[offset]={i*20}&quot;
    response = requests.get(url)

    if response.status_code != 200:
        print('Error with status code:', response.status_code)
        continue

    data = response.json()['data']

    for anime in data:
        anime_id = anime['id']
        url = f&quot;https://kitsu.io/api/edge/media-reactions?filter[animeId]={anime_id}&amp;page[limit]=5&quot;
        response = requests.get(url)

        if response.status_code != 200:
            print(f&quot;Error with status code for Anime ID {anime_id}: {response.status_code}&quot;)
            continue

        reactions = response.json()['data']

        # å¯¹kitsuè¯„è®ºè¿›è¡Œé¢„æµ‹å¹¶å°†é¢„æµ‹ç»“æœå‘é€åˆ°Kafka
        for reaction in reactions:
            reaction_content = reaction['attributes']['reaction']
            sentiment_prediction = predict_sentiment(reaction_content)  # directly call the function here
            print(sentiment_prediction)

            # å°†updatedAtä½œä¸ºkey
            reaction_updatedAt = reaction['attributes']['updatedAt']
            reaction_key = get_timestamp_from_iso8601(reaction_updatedAt)

            # Create a JSON object that includes the key and value
            sentiment_json = json.dumps({&quot;timestamp&quot;: reaction_key, &quot;sentiment&quot;: sentiment_prediction})
            
            # Send the JSON object to Kafka with a dummy key (or you can leave the key=None)
            producer.produce(topic='prediction_topics', value=sentiment_json)  

# Ensure all messages are sent
producer.flush()
</code></pre>
<h3 id="å¯è§†åŒ–">å¯è§†åŒ–</h3>
<p>ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œæˆ‘ä»¬å›åˆ°composerï¼ˆairflowï¼‰æ§åˆ¶å°ï¼Œç‚¹å‡»æ‰“å¼€airflowç•Œé¢ï¼š</p>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133045.png" alt="" loading="lazy"></figure>
<p>æ¥åˆ°ç†Ÿæ‚‰çš„ç•Œé¢ï¼Œå¦‚æœDAGç¼–å†™æ²¡æœ‰é—®é¢˜ï¼Œä½ å°±å¯ä»¥è§¦å‘dagäº†ã€‚</p>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133129.png" alt="" loading="lazy"></figure>
<p>æœ€ç»ˆæˆ‘ä»¬çš„ä¸‰ä¸ªtopicéƒ½åœ¨elkå¹³å°ä¸Šè¢«æ¶ˆè´¹åï¼Œä¼šå‡ºç°åœ¨è¿™é‡Œï¼š</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133248.png" alt="" loading="lazy"></figure>
<p>æ¥ä¸‹æ¥å°±æ˜¯åˆ›å»ºdataviewå’Œä½¿ç”¨dashboardè¿›è¡Œå¯è§†åŒ–äº†ã€‚</p>
<p>å·¦è¾¹æ‹‰åˆ°åº•é€‰æ‹©stack managementï¼Œå†é€‰æ‹©dataviewï¼Œæˆ‘è¿™é‡Œåˆ›å»ºäº†ä¸¤ä¸ªdata viewï¼š</p>
<figure data-type="image" tabindex="17"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133505.png" alt="" loading="lazy"></figure>
<p>ç„¶åæˆ‘ä»¬å°±å¯ä»¥å»elkçš„dashboardè¿›è¡Œå¯è§†åŒ–æ“ä½œäº†ã€‚</p>
<p>å¦‚æœæœ‰å®æ—¶çš„æ•ˆæœï¼Œè¦å¦‚ä¸‹è®¾ç½®ï¼Œrefreshè®¾ç½®ä¸º1sï¼š</p>
<figure data-type="image" tabindex="18"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133704.png" alt="" loading="lazy"></figure>
<p>æœ€ååšä¸€ä¸ªå±•ç¤ºï¼š</p>
<figure data-type="image" tabindex="19"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230528133813.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[æ•°æ®æ± ä¸å¤§æ•°æ®åˆ†æå¯è§†åŒ–ç»¼åˆåº”ç”¨çš„æ¢ç´¢]]></title>
        <id>https://gagumi.github.io/post/shu-ju-chi-yu-da-shu-ju-fen-xi-ke-shi-hua-zong-he-ying-yong-de-tan-suo/</id>
        <link href="https://gagumi.github.io/post/shu-ju-chi-yu-da-shu-ju-fen-xi-ke-shi-hua-zong-he-ying-yong-de-tan-suo/">
        </link>
        <updated>2023-05-24T15:47:20.000Z</updated>
        <summary type="html"><![CDATA[<p style="font-size:20px;">å­¦æ ¡çš„ä¸€ä¸ªprojectï¼Œè¦æ±‚å®Œæˆä¸€æ•´å¥—çš„å¤§æ•°æ®æµç¨‹ã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
]]></summary>
        <content type="html"><![CDATA[<p style="font-size:20px;">å­¦æ ¡çš„ä¸€ä¸ªprojectï¼Œè¦æ±‚å®Œæˆä¸€æ•´å¥—çš„å¤§æ•°æ®æµç¨‹ã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
<!-- more -->
<h3 id="å‰æœŸæ€è·¯">å‰æœŸæ€è·¯</h3>
<p>å†³å®šåšå››ä¸ªå¯è§†åŒ–ï¼š</p>
<ul>
<li>
<p>å®æ—¶è¯„åˆ†è·Ÿè¸ª</p>
</li>
<li>
<p>å®æ—¶è¯„è®ºæƒ…ç»ªåˆ†æ</p>
</li>
<li>
<p>å„ä¸ªç±»åˆ«çš„åŠ¨æ¼«åœ¨ä¸åŒæ—¶é—´æ®µçš„å‘å¸ƒæ•°é‡</p>
</li>
<li>
<p>å®æ—¶çƒ­åº¦æ’è¡Œ</p>
</li>
</ul>
<p>å¤§è‡´æ€è·¯ä¸ºï¼š</p>
<ul>
<li>æ•°æ®å‡†å¤‡ï¼š</li>
</ul>
<p>æ¢ç´¢MyAnimeList APIå’ŒKitsu API</p>
<ul>
<li>
<p>æ•°æ®æ”¶é›†ï¼š</p>
<p>åˆ›å»ºä¸€ä¸ª Airflow ä»»åŠ¡æ¥å®šæœŸè°ƒç”¨ MyAnimeList API å’Œ Kitsu APIï¼Œè·å–åŠ¨æ¼«æ•°æ®ã€‚è¿™ä¸ªä»»åŠ¡å¯èƒ½éœ€è¦ä¸€ä¸ª Python è„šæœ¬æ¥è°ƒç”¨ APIï¼Œå¹¶å¤„ç†è¿”å›çš„æ•°æ®ã€‚<br>
å°†è·å–çš„æ•°æ®å‘é€åˆ° Kafka ä¸­ã€‚è¿™å¯ä»¥é€šè¿‡ Kafka çš„ Python å®¢æˆ·ç«¯åº“å®Œæˆï¼Œä¾‹å¦‚ Confluent Kafka Pythonã€‚</p>
</li>
<li>
<p>å®æ—¶æ•°æ®å¤„ç†ï¼š</p>
<p>åˆ›å»ºä¸€ä¸ª Airflow ä»»åŠ¡æ¥å¯åŠ¨ Spark Streaming ä½œä¸šï¼Œä» Kafka ä¸­è¯»å–æ•°æ®ï¼Œå¹¶è¿›è¡Œå®æ—¶æ•°æ®å¤„ç†ã€‚è¿™ä¸ª Spark Streaming ä½œä¸šéœ€è¦è¿›è¡Œä¸€äº›æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†æ­¥éª¤ï¼Œä¾‹å¦‚å»é™¤æ— æ•ˆçš„æ•°æ®ï¼Œæˆ–è€…è½¬æ¢æ•°æ®çš„æ ¼å¼ã€‚</p>
</li>
<li>
<p>æ•°æ®è½¬æ¢ï¼š</p>
<p>åˆ›å»ºä¸€ä¸ª Airflow ä»»åŠ¡æ¥å¯åŠ¨ Spark ä½œä¸šï¼Œè¿›è¡Œæ•°æ®è½¬æ¢ã€‚</p>
<p>è¿™ä¸ª Spark ä½œä¸šéœ€è¦å°†æ•°æ®è½¬æ¢ä¸º Parquet æ ¼å¼ï¼Œæˆ–è€…å°†æ—¥æœŸå­—æ®µè½¬æ¢ä¸º UTC æ ¼å¼ã€‚</p>
</li>
<li>
<p>æƒ…ç»ªåˆ†æï¼š</p>
<p>åˆ›å»ºä¸€ä¸ª Airflow ä»»åŠ¡æ¥å¯åŠ¨ Spark MLlib ä½œä¸šï¼Œè¿›è¡Œæƒ…ç»ªåˆ†æã€‚</p>
<p>è¿™ä¸ªä»»åŠ¡å¯èƒ½éœ€è¦ä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ–è€…è‡ªå·±çš„æ¨¡å‹ï¼Œå¯¹ç”¨æˆ·è¯„è®ºè¿›è¡Œæƒ…ç»ªåˆ†æã€‚</p>
</li>
<li>
<p>æ•°æ®å­˜å‚¨ï¼š</p>
<p>åˆ›å»ºä¸€ä¸ª Airflow ä»»åŠ¡æ¥å°†å¤„ç†åçš„æ•°æ®å­˜å‚¨åœ¨ Elasticsearch ä¸­ã€‚</p>
<p>éœ€è¦åˆ›å»ºä¸€ä¸ª Elasticsearch ç´¢å¼•æ¥å­˜å‚¨æ•°æ®ã€‚ä½¿ç”¨ Elasticsearch çš„ Python å®¢æˆ·ç«¯åº“ï¼Œä¾‹å¦‚ elasticsearch-pyï¼Œæ¥è¿›è¡Œè¿™ä¸ªæ“ä½œã€‚</p>
</li>
<li>
<p>æ•°æ®å¯è§†åŒ–ï¼š</p>
<p>åœ¨ Grafana ä¸­åˆ›å»ºä¸€ä¸ªæˆ–å¤šä¸ªä»ªè¡¨ç›˜æ¥å±•ç¤ºä½ çš„æ•°æ®ã€‚è¿™ä¸€æ­¥å¯èƒ½ä¸éœ€è¦åœ¨ Airflow ä¸­è¿›è¡Œï¼Œéœ€è¦å®šæœŸæ›´æ–°ä½ çš„ Grafana ä»ªè¡¨ç›˜ã€‚</p>
</li>
<li>
<p>æ•°æ®åˆ†æï¼š</p>
<p>æ ¹æ®éœ€æ±‚å’Œå¯è§†åŒ–ç»“æœï¼Œåˆ›å»ºä¸‰ä¸ª Airflow ä»»åŠ¡æ¥å¯åŠ¨ Spark  ä½œä¸šï¼Œè¿›è¡Œè¿›ä¸€æ­¥çš„æ•°æ®åˆ†æï¼ˆå®æ—¶è¯„åˆ†è·Ÿè¸ªï¼Œå„ä¸ªç±»åˆ«çš„åŠ¨æ¼«åœ¨ä¸åŒæ—¶é—´æ®µçš„å‘å¸ƒæ•°é‡ï¼Œå®æ—¶çƒ­åº¦æ’è¡Œï¼‰ã€‚</p>
</li>
</ul>
<h3 id="æœŸæœ›è¿”å›æ•°æ®">æœŸæœ›è¿”å›æ•°æ®</h3>
<ol>
<li>
<p><strong>åŠ¨æ¼«åŸºç¡€ä¿¡æ¯</strong>ï¼šè¿™å¯èƒ½åŒ…æ‹¬åŠ¨æ¼«çš„åç§°ï¼Œæè¿°ï¼Œç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œæ˜¯ç”µè§†å‰§ã€ç”µå½±è¿˜æ˜¯OVAï¼‰ï¼Œå¹´ä»½ï¼Œå­£åº¦ï¼Œåˆ¶ä½œå…¬å¸ï¼Œå¯¼æ¼”ç­‰ã€‚</p>
</li>
<li>
<p><strong>ç”¨æˆ·è¯„åˆ†</strong>ï¼šç”¨æˆ·å¯¹åŠ¨æ¼«çš„è¯„åˆ†é€šå¸¸æ˜¯é‡è¦çš„åˆ†ææŒ‡æ ‡ã€‚å¯èƒ½éœ€è¦äº†è§£è¯„åˆ†çš„èŒƒå›´ï¼ˆä¾‹å¦‚ï¼Œæ˜¯1-5ï¼Œè¿˜æ˜¯1-10ï¼‰ï¼Œä»¥åŠè¯„åˆ†æ˜¯å¦‚ä½•è®¡ç®—çš„ï¼ˆä¾‹å¦‚ï¼Œæ˜¯å¹³å‡è¯„åˆ†ï¼Œè¿˜æ˜¯ä¸­ä½æ•°è¯„åˆ†ï¼‰ã€‚</p>
</li>
<li>
<p><strong>ç”¨æˆ·è¯„è®º</strong>ï¼šç”¨æˆ·çš„æ–‡å­—è¯„è®ºå¯ä»¥ç”¨äºæƒ…ç»ªåˆ†æã€‚æ³¨æ„ï¼Œå¯èƒ½éœ€è¦é¢å¤–çš„æ•°æ®å¤„ç†æ­¥éª¤ï¼Œä¾‹å¦‚æ–‡æœ¬æ¸…æ´—å’Œé¢„å¤„ç†ã€‚</p>
</li>
<li>
<p><strong>åŠ¨æ¼«çš„è§‚çœ‹æ•°é‡æˆ–çƒ­åº¦</strong>ï¼šè¿™å¯èƒ½ç”±æŸç§æŒ‡æ ‡è¡¨ç¤ºï¼Œä¾‹å¦‚ç”¨æˆ·è§‚çœ‹çš„æ¬¡æ•°ï¼Œæˆ–è€…ç”¨æˆ·å¯¹åŠ¨æ¼«çš„å–œæ¬¢ç¨‹åº¦</p>
</li>
<li>
<p><strong>æ—¶é—´æˆ³</strong>ï¼šè¿™æ˜¯å®æ—¶åˆ†ææ‰€å¿…éœ€çš„ã€‚æ—¶é—´æˆ³å¯ä»¥å¸®åŠ©äº†è§£è¯„è®ºæˆ–è¯„åˆ†æ˜¯ä½•æ—¶è¢«æäº¤çš„ã€‚</p>
</li>
</ol>
<h3 id="apiæ¢ç´¢myanimelist-api">APIæ¢ç´¢ï¼šMyAnimeList API</h3>
<p>æŸ¥çœ‹ MyAnimeList å®˜æ–¹æ–‡æ¡£ï¼Œå‘ç°å…¶è¿”å›åŠŸèƒ½è¾ƒå°‘ã€‚è¿™é‡Œå†³å®šé‡‡ç”¨https://api.jikan.moe/v4 APIä»£ä¸ºæŠ“å–ä¿¡æ¯ã€‚</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230523100244.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230525175011.png" alt="" loading="lazy"></figure>
<p>åœ¨å…¶ä¸­æµè§ˆï¼Œå‘ç°ä»¥ä¸Šä¸¤ä¸ªGETçš„è¿”å›å€¼èƒ½å¤Ÿå®Œæˆæˆ‘ä»¬çš„é¢„æœŸä»»åŠ¡ã€‚å†³å®šä»¥ç‹‚èµŒä¹‹æ¸Šï¼ˆIDï¼š34933 å§å§è¸©æˆ‘ï¼‰ä¸ºä¾‹ï¼Œè¿›è¡ŒAPIæ¢ç´¢ã€‚<br>
è€ƒè™‘åˆ°è®¿é—®é™åˆ¶ï¼Œé¢„æœŸåªè¿”å›å‰äº”æ¡è¯„è®ºã€‚å…ˆåšä¸€ä¸ªç®€å•çš„å°è¯•ã€‚</p>
<pre><code class="language-python">import requests

def get_anime_info_and_top_reviews(anime_id, review_count=5):
    # Define the base URL for the Jikan API
    base_url = &quot;https://api.jikan.moe/v4&quot;

    # Create the URLs for the specific anime and its reviews
    anime_url = f&quot;{base_url}/anime/{anime_id}/full&quot;
    review_url = f&quot;{base_url}/anime/{anime_id}/reviews&quot;

    # Send a GET request to the Jikan API for the anime info
    anime_response = requests.get(anime_url)

    # If the GET request is successful, the status code will be 200
    if anime_response.status_code == 200:
        # Get the JSON data from the response
        anime_data = anime_response.json()

        # Access the 'data' field in the response
        anime_info = anime_data[&quot;data&quot;]

        # Print the title, type, airing dates, score, and popularity of the anime
        print(f&quot;Title: {anime_info['title']}&quot;)
        print(f&quot;Type: {anime_info['type']}&quot;)
        print(f&quot;Aired: {anime_info['aired']}&quot;)
        print(f&quot;Score: {anime_info['score']}&quot;)
        print(f&quot;Popularity: {anime_info['popularity']}&quot;)

    # Send a GET request to the Jikan API for the anime reviews
    review_response = requests.get(review_url)

    # If the GET request is successful, the status code will be 200
    if review_response.status_code == 200:
        # Get the JSON data from the response
        review_data = review_response.json()

        # Access the 'data' field in the response
        reviews = review_data[&quot;data&quot;]

        # Limit the number of reviews to the specified review count
        reviews = reviews[:review_count]

        # Iterate over each review
        for review in reviews:
            # Print the username of the reviewer and the review text
            print(f&quot;\nUsername: {review['user']['username']}&quot;)
            print(f&quot;Review: {review['review']}&quot;)
            print(f&quot;Score: {review['score']}&quot;)
            print(f&quot;Date: {review['date']}&quot;)

# Test the function with the anime ID for Kakegurui (ID 34933)
get_anime_info_and_top_reviews(34933)

</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230523100939.png" alt="" loading="lazy"></figure>
<p>æˆ‘æ‰€éœ€è¦çš„åŠ¨æ¼«ä¿¡æ¯çš„è¿”å›éå¸¸æˆåŠŸï¼Œæ¥ä¸‹æ¥æ˜¯è¯„è®ºï¼Œç¡®å®è¾“å‡ºäº†è¯„è®ºçš„å‰äº”æ¡ï¼ˆJikan API çš„ &quot;/reviews&quot; ç«¯ç‚¹è¿”å›çš„è¯„è®ºæ˜¯æŒ‰ç…§æŸç§æ–¹å¼æ’åºçš„ï¼Œè™½ç„¶å…·ä½“çš„æ’åºè§„åˆ™åœ¨ API æ–‡æ¡£ä¸­å¹¶æœªæ˜ç¡®è¯´æ˜ï¼Œç¦»è°±ï¼‰ï¼Œå°è¯•å¤šæ¬¡è¯·æ±‚è¿”å›ç»“æœç›¸åŒã€‚</p>
<h3 id="æœ‰å…³myanimelistçš„æ€è€ƒ">æœ‰å…³MyAnimeListçš„æ€è€ƒ</h3>
<p>ç”±äºå…¶topæ¦œå•æ›´æ–°æ—¶é—´ä¸ºæ¯ä¸¤å¤©æ›´æ–°ä¸€æ¬¡ï¼Œä¸”æ²¡æœ‰å†å²æ•°æ®ï¼Œå¯¼è‡´åªèƒ½å®ç°å®šæœŸæ”¶é›†topæ¦œå•æ•°æ®ï¼Œè¯„è®ºæ•°æ®ã€‚</p>
<p>é‚£ä¹ˆæˆ‘ä»¬çš„ç›®æ ‡å°±æ¼”å˜æˆï¼š</p>
<ul>
<li><strong>å®æ—¶æœç´¢ä½ æƒ³è¦çš„ç•ªå‰§</strong>ï¼Œè¿”å›å…¶å°é¢ï¼ŒRanked ï¼ŒPopularityï¼Œç®€ä»‹ä»¥åŠå¯¹æœ€è¿‘äº”æ¡è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚</li>
<li><strong>å®æ—¶æ˜¾ç¤ºå½“å‰æœ€å—æ¬¢è¿çš„åŠ¨ç”»</strong>ï¼Œå±•ç¤ºå…¶å°é¢ï¼ŒRanked ï¼ŒPopularityï¼Œç®€ä»‹ä»¥åŠå¯¹æœ€è¿‘äº”æ¡è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚</li>
<li><strong>åŠ¨ç”»ç±»å‹çš„åˆ†å¸ƒ</strong>ï¼šå¯ä»¥ç»Ÿè®¡åº“ä¸­æ‰€æœ‰åŠ¨ç”»çš„ç±»å‹ï¼ˆå¦‚åŠ¨ä½œã€å†’é™©ã€æ‚¬ç–‘ç­‰ï¼‰ï¼Œå¹¶é€šè¿‡é¥¼çŠ¶å›¾æˆ–æ¡å½¢å›¾æ¥æ˜¾ç¤ºå„ç±»å‹åŠ¨ç”»çš„åˆ†å¸ƒã€‚ï¼ˆé€šè¿‡é€‰æ‹©æ—¶é—´æ®µæ¥è¿›è¡Œæ”¹å˜ï¼‰</li>
<li><strong>åŠ¨ç”»æ’­æ”¾æ—¶æ®µ</strong>ï¼šåˆ†æå’Œå±•ç¤ºåŠ¨ç”»çš„æ’­æ”¾æ—¶æ®µï¼Œæ¯”å¦‚å“ªä¸ªå­£åº¦æˆ–å“ªä¸ªæœˆä»½æ’­æ”¾çš„åŠ¨ç”»æ•°é‡æœ€å¤šï¼ˆé€šè¿‡é€‰æ‹©å­£åº¦ï¼‰ã€‚</li>
<li>å®æ—¶åŠŸèƒ½å®ç°ï¼šæ¯å¤©è·å–ä¸¤æ¬¡TOP50æ¦œå•ã€‚</li>
<li>å®æ—¶åŠŸèƒ½å®ç°ï¼šå®šæœŸåœ°ï¼ˆä¾‹å¦‚æ¯å¤©æˆ–æ¯å°æ—¶ï¼‰è·å–TOP50çš„æœ€æ–°è¯„è®ºï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨è‡ªå·±çš„æ•°æ®åº“ä¸­ï¼Œé™„å¸¦è·å–è¯„è®ºçš„æ—¥æœŸã€‚ç„¶åï¼Œå¯ä»¥åœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢ç‰¹å®šæ—¶é—´æ®µçš„è¯„è®ºã€‚åœ¨ MyAnimeList çš„è¯„è®ºæ•°æ®ä¸­ï¼Œ<code>mal_id</code>å­—æ®µæ˜¯æ¯æ¡è¯„è®ºçš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚å¯ä»¥ä½¿ç”¨è¿™ä¸ªå­—æ®µæ¥æ£€æŸ¥æ–°è·å–çš„è¯„è®ºæ˜¯å¦å·²ç»åœ¨æ•°æ®åº“ä¸­ã€‚</li>
</ul>
<h3 id="å…³äºæ‰€æœ‰åŠ¨ç”»">å…³äºæ‰€æœ‰åŠ¨ç”»</h3>
<p>TMDï¼Œç”±äºJikan APIå¹¶ä¸å…è®¸è·å–æ‰€æœ‰åŠ¨ç”»ï¼Œæ‰€ä»¥åªèƒ½ä½¿ç”¨<code>top</code>ç«¯ç‚¹æ¥è·å–å‰50åçš„åŠ¨ç”»ï¼Œå¹¶ä»ä¸­æå–ç±»å‹ä¿¡æ¯ã€‚è¿›è¡Œå°è¯•ã€‚</p>
<p>è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œå…¶TOPè¯·æ±‚çš„å‚æ•°å¦‚ä¸‹ä¾‹å­ï¼š</p>
<pre><code class="language-python">params = {
    'type': 'tv',
    'filter': 'airing',
    'page': 1,
    'limit': 50
}
</code></pre>
<p>é‚£ä¹ˆä¼°è®¡å…¶è¯·æ±‚åº”è¯¥ä¸ºhttps://api.jikan.moe/v4/anime?filter=bypopularity&amp;page=1&amp;limit=50</p>
<p>æ‹¿åˆ°äº†ç»“æœï¼Œæ­¤æ—¶å†é€šè¿‡æ¯ä¸ªåŠ¨æ¼«çš„mal_idæ¥æŸ¥æ‰¾å¹¶è·å–èµ„æº</p>
<pre><code class="language-python">import time
import requests
from collections import defaultdict
import matplotlib.pyplot as plt

# åˆ›å»ºä¸€ä¸ªé»˜è®¤å­—å…¸æ¥å­˜å‚¨æ¯ä¸ªç±»å‹çš„æ•°é‡
genre_counts = defaultdict(int)

# è·å–å‰50åçš„åŠ¨ç”»
response = requests.get(&quot;https://api.jikan.moe/v4/anime?filter=bypopularity&amp;page=1&amp;limit=50&quot;)
top_50_anime = response.json()

for anime in top_50_anime['data']:
    # å¯¹æ¯ä¸ªåŠ¨ç”»å‘é€ä¸€ä¸ªè¯·æ±‚ï¼Œè·å–å…¶è¯¦ç»†ä¿¡æ¯
    response = requests.get(f&quot;https://api.jikan.moe/v4/anime/{anime['mal_id']}&quot;)
    anime_detail = response.json()

    # éå†åŠ¨ç”»çš„æ‰€æœ‰ç±»å‹ï¼Œå¢åŠ è®¡æ•°
    for genre in anime_detail['data']['genres']:
        genre_counts[genre['name']] += 1

    # ä¼‘çœ 1ç§’ï¼Œä»¥é¿å…å‘é€è¿‡å¤šçš„è¯·æ±‚
    time.sleep(1)

# æ‰“å°æ¯ä¸ªç±»å‹çš„æ•°é‡
for genre, count in genre_counts.items():
    print(f&quot;{genre}: {count}&quot;)

# å‡†å¤‡æ•°æ®
genres = list(genre_counts.keys())
counts = list(genre_counts.values())

# åˆ›å»ºæ¡å½¢å›¾
plt.figure(figsize=(10,6))
plt.barh(genres, counts, color='skyblue')  # ä½¿ç”¨æ°´å¹³æ¡å½¢å›¾ barhï¼Œæ–¹ä¾¿æ ‡ç­¾çš„æ˜¾ç¤º

# è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
plt.title('Genre Distribution of Top 50 Anime')
plt.xlabel('Count')
plt.ylabel('Genre')

# æ˜¾ç¤ºå›¾è¡¨
plt.show()
</code></pre>
<p>å…¶ç»“æœå¦‚ä¸‹ï¼š</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/image-20230523125808624.png" alt="" loading="lazy"></figure>
<p>è¿™æ ·çš„ç»“æœä¸ä¸»é¡µæ˜¾ç¤ºçš„å†…å®¹ç›¸æ‚–ï¼Œéœ€è¦é‡æ–°é€‰æ‹©urlæ¥å‘é€è¯·æ±‚ã€‚</p>
<p>https://api.jikan.moe/v4/top/anime?page=1<br>
è™½ç„¶åœ¨å®˜ç½‘ä¸Šçœ‹èµ·æ¥ä¸€é¡µæœ‰50ä¸ªåŠ¨æ¼«ï¼Œä½†æ˜¯ï¼Œç»è¿‡è§‚å¯Ÿè¿”å›å€¼ï¼Œå¯ä»¥å‘ç°ï¼Œä¸€é¡µå…¶å®æ˜¯25ä¸ªåŠ¨æ¼«ï¼Œé‚£ä¹ˆï¼Œæˆ‘ä»¬è¿˜éœ€è¦éå†1 ï¼Œ2ã€‚</p>
<pre><code class="language-python">import time
import requests
from collections import defaultdict
import matplotlib.pyplot as plt

# åˆ›å»ºä¸€ä¸ªé»˜è®¤å­—å…¸æ¥å­˜å‚¨æ¯ä¸ªç±»å‹çš„æ•°é‡
genre_counts = defaultdict(int)

# è·å–å‰50åçš„åŠ¨ç”»ï¼Œé€šè¿‡ä¸¤æ¬¡å¾ªç¯è·å–ç¬¬1é¡µå’Œç¬¬2é¡µçš„æ•°æ®
for page in [1, 2]:
    response = requests.get(f&quot;https://api.jikan.moe/v4/top/anime?page={page}&quot;)
    top_anime = response.json()

    for anime in top_anime['data']:
        # å¯¹æ¯ä¸ªåŠ¨ç”»å‘é€ä¸€ä¸ªè¯·æ±‚ï¼Œè·å–å…¶è¯¦ç»†ä¿¡æ¯
        response = requests.get(f&quot;https://api.jikan.moe/v4/anime/{anime['mal_id']}&quot;)
        anime_detail = response.json()

        # æ‰“å°åŠ¨ç”»çš„åå­—
        print(f&quot;Anime name: {anime_detail['data']['title']}&quot;)

        # éå†åŠ¨ç”»çš„æ‰€æœ‰ç±»å‹ï¼Œå¢åŠ è®¡æ•°
        for genre in anime_detail['data']['genres']:
            genre_counts[genre['name']] += 1

        # ä¼‘çœ 1ç§’ï¼Œä»¥é¿å…å‘é€è¿‡å¤šçš„è¯·æ±‚
        time.sleep(1)

# æ‰“å°æ¯ä¸ªç±»å‹çš„æ•°é‡
for genre, count in genre_counts.items():
    print(f&quot;{genre}: {count}&quot;)

# å‡†å¤‡æ•°æ®
genres = list(genre_counts.keys())
counts = list(genre_counts.values())

# åˆ›å»ºæ¡å½¢å›¾
plt.figure(figsize=(10,6))
plt.barh(genres, counts, color='skyblue')  # ä½¿ç”¨æ°´å¹³æ¡å½¢å›¾ barhï¼Œæ–¹ä¾¿æ ‡ç­¾çš„æ˜¾ç¤º

# è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
plt.title('Genre Distribution of Top 50 Anime')
plt.xlabel('Count')
plt.ylabel('Genre')

# æ˜¾ç¤ºå›¾è¡¨
plt.show()
</code></pre>
<p>ç»“æœæ­£å¸¸</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230523131848.png" alt="" loading="lazy"></figure>
<p>ä¸‹é¢æ˜¯ç»Ÿè®¡å›¾ï¼š</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230523132046.png" alt="" loading="lazy"></figure>
<h4 id="é€šè¿‡sesonæŠ“å–åŠ¨ç”»åç§°ç­‰å†…å®¹2006-2023">é€šè¿‡sesonæŠ“å–åŠ¨ç”»åç§°ç­‰å†…å®¹ï¼ˆ2006-2023ï¼‰</h4>
<p>å°†é¡¹ç›®è¿ç§»åˆ°colabä¸Šï¼ŒæœŸæœ›è¾“å‡º&quot;Year&quot;, &quot;Season&quot;, &quot;Anime Name&quot;, &quot;Score&quot;, &quot;MAL ID&quot;ï¼Œè¿›è¡Œè¯•è¿è¡Œçš„æ—¶å€™å‡ºç°é—®é¢˜ï¼Œå¾ˆå¤šè€æ—¥æ¼«æ²¡æœ‰è‹±æ–‡åå­—ã€‚</p>
<p>ä¸€å¼€å§‹ä½¿ç”¨ç½—é©¬éŸ³ç¿»è¯‘ï¼Œå‡ºç°é—®é¢˜ä¸”è¡¨æ„å¯èƒ½ä¸å‡†ç¡®ï¼Œäºæ˜¯ä½¿ç”¨translationåº“ï¼Œå¦‚æœæ²¡æœ‰è‹±æ–‡æ ‡é¢˜ï¼Œå°†å…¶ç¿»è¯‘ä¸ºæ—¥è¯­ã€‚</p>
<p>é¡ºä¾¿å°†å¾—åˆ°çš„ç»“æœå­˜å…¥csvä¸­ã€‚</p>
<pre><code class="language-python">import csv
import requests
import time
from translate import Translator

translator = Translator(from_lang='ja', to_lang='en')

years = range(2006, 2024)
seasons = ['winter', 'spring', 'summer', 'fall']
anime_data = []

for year in years:
    for season in seasons:
        response = requests.get(f&quot;https://api.jikan.moe/v4/seasons/{year}/{season}&quot;)
        data = response.json()
        last_page = data['pagination']['last_visible_page']
        for page in range(1, last_page + 1):
            response = requests.get(f&quot;https://api.jikan.moe/v4/seasons/{year}/{season}?page={page}&quot;)
            data = response.json()
            for anime in data['data']:
                anime_name = None
                anime_id = anime['mal_id']
                for title_info in anime['titles']:
                    if title_info['type'] == 'English':
                        anime_name = title_info['title']
                        break
                if anime_name is None:
                    # English title is missing, use translation
                    japanese_title = anime['title_japanese']
                    anime_name = translator.translate(japanese_title)
                anime_score = anime['score']
                print(f&quot;Year: {year}, Anime: {anime_name}, MAL ID: {anime_id}&quot;)
                anime_data.append([year, season, anime_name, anime_score, anime_id])
            time.sleep(1)

with open('anime_seasons.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow([&quot;Year&quot;, &quot;Season&quot;, &quot;Anime Name&quot;, &quot;Score&quot;, &quot;MAL ID&quot;])
    writer.writerows(anime_data)
</code></pre>
<p>æŠ“å–ç»“æœè¾ƒå·®ï¼Œæœ‰å‡ ç‡å‡ºç°ç©ºçš„è¿”å›å€¼ã€‚<br>
æ”¾å¼ƒç¿»è¯‘ï¼Œæ²¡æœ‰è‹±æ–‡æ ‡é¢˜çš„ç›´æ¥è®°å½•æ—¥è¯­æ ‡é¢˜ã€‚</p>
<p>æŠ“ä¸‹æ¥æ•°æ®ä¹‹åï¼Œå‡†å¤‡å·¥ä½œå®Œæˆã€‚</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[# æœ‰å…³ELKçš„å®‰è£…ä¸ä½¿ç”¨]]></title>
        <id>https://gagumi.github.io/post/you-guan-elk-de-an-zhuang-yu-shi-yong/</id>
        <link href="https://gagumi.github.io/post/you-guan-elk-de-an-zhuang-yu-shi-yong/">
        </link>
        <updated>2023-05-14T20:30:08.000Z</updated>
        <summary type="html"><![CDATA[<p style="font-size:20px;">ELK æ˜¯ä¸€ä¸ªå¼€æºè½¯ä»¶å †æ ˆï¼Œç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼šElasticsearchã€Logstash å’Œ Kibanaã€‚æ¯ä¸ªç»„ä»¶éƒ½å…·æœ‰ä¸åŒçš„åŠŸèƒ½ï¼Œå…±åŒæ„å»ºäº†ä¸€ä¸ªå¼ºå¤§çš„æ—¥å¿—ç®¡ç†å’Œåˆ†æå¹³å°ã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
]]></summary>
        <content type="html"><![CDATA[<p style="font-size:20px;">ELK æ˜¯ä¸€ä¸ªå¼€æºè½¯ä»¶å †æ ˆï¼Œç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼šElasticsearchã€Logstash å’Œ Kibanaã€‚æ¯ä¸ªç»„ä»¶éƒ½å…·æœ‰ä¸åŒçš„åŠŸèƒ½ï¼Œå…±åŒæ„å»ºäº†ä¸€ä¸ªå¼ºå¤§çš„æ—¥å¿—ç®¡ç†å’Œåˆ†æå¹³å°ã€‚
</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3" loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
<!-- more -->
<p>å­¦æ ¡æä¾›äº†å››ä¸ªæœˆçš„ä½¿ç”¨èµ„æ ¼ï¼Œä½†æ˜¯æ˜¾ç¤ºåªæ˜¾ç¤º14å¤©ã€‚</p>
<p>ä»¥ä¸‹æ˜¯æ¯ä¸ªç»„ä»¶çš„ç®€è¦ä»‹ç»ï¼š</p>
<p>Elasticsearchï¼šElasticsearch æ˜¯ä¸€ä¸ªå®æ—¶åˆ†å¸ƒå¼æœç´¢å’Œåˆ†æå¼•æ“ï¼Œç”¨äºå­˜å‚¨ã€æœç´¢å’Œåˆ†æå¤§è§„æ¨¡æ•°æ®ã€‚å®ƒè¢«è®¾è®¡ç”¨äºé«˜å¯æ‰©å±•æ€§å’Œå®¹é”™æ€§ï¼Œå¯ä»¥å¤„ç†æµ·é‡æ•°æ®ï¼Œå¹¶æä¾›å¼ºå¤§çš„å…¨æ–‡æœç´¢ã€å¤æ‚æŸ¥è¯¢ã€èšåˆå’Œåˆ†æèƒ½åŠ›ã€‚</p>
<p>Logstashï¼šLogstash æ˜¯ä¸€ä¸ªç”¨äºæ•°æ®æ”¶é›†ã€å¤„ç†å’Œä¼ è¾“çš„å¼€æºå·¥å…·ã€‚å®ƒå¯ä»¥ä»å„ç§æ¥æºï¼ˆå¦‚æ—¥å¿—æ–‡ä»¶ã€æ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰ï¼‰æ”¶é›†æ•°æ®ï¼Œå¹¶å°†å…¶è¿›è¡Œè½¬æ¢ã€æ ‡å‡†åŒ–å’Œè¿‡æ»¤ï¼Œç„¶åå‘é€åˆ°ä¸åŒçš„ç›®æ ‡ï¼Œå…¶ä¸­åŒ…æ‹¬ Elasticsearchã€‚</p>
<p>Kibanaï¼šKibana æ˜¯ä¸€ä¸ªç”¨äºæ•°æ®å¯è§†åŒ–å’Œåˆ†æçš„å¼€æºå·¥å…·ã€‚å®ƒæä¾›äº†ç›´è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡äº¤äº’å¼å›¾è¡¨ã€ä»ªè¡¨ç›˜ã€åœ°å›¾ç­‰æ–¹å¼æ¥æ¢ç´¢å’Œå¯è§†åŒ– Elasticsearch ä¸­çš„æ•°æ®ã€‚Kibana æä¾›äº†ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä»¥ç›´è§‚çš„æ–¹å¼ç†è§£å’Œåˆ†ææ•°æ®ã€‚</p>
<p>è¿™ä¸‰ä¸ªç»„ä»¶å…±åŒåä½œï¼Œæ„å»ºäº†ä¸€ä¸ªå¼ºå¤§çš„æ—¥å¿—ç®¡ç†å’Œåˆ†æå¹³å°ã€‚Logstash ç”¨äºæ”¶é›†å’Œå¤„ç†æ•°æ®ï¼ŒElasticsearch ç”¨äºå­˜å‚¨å’Œç´¢å¼•æ•°æ®ï¼Œè€Œ Kibana åˆ™æä¾›äº†äº¤äº’å¼çš„æ•°æ®å¯è§†åŒ–å’Œåˆ†æç•Œé¢ã€‚</p>
<p>ELK è¢«å¹¿æ³›åº”ç”¨äºæ—¥å¿—ç®¡ç†ã€å®æ—¶ç›‘æ§ã€æ•°æ®åˆ†æå’Œä¸šåŠ¡æ™ºèƒ½ç­‰é¢†åŸŸã€‚å®ƒèƒ½å¤Ÿå¤„ç†å’Œåˆ†æå„ç§ç±»å‹çš„æ•°æ®ï¼ŒåŒ…æ‹¬æ—¥å¿—æ•°æ®ã€æŒ‡æ ‡æ•°æ®ã€æ–‡æœ¬æ•°æ®ç­‰ï¼Œå¸®åŠ©ç”¨æˆ·å‘ç°æ½œåœ¨çš„é—®é¢˜ã€è·å¾—å®æ—¶è§è§£ï¼Œå¹¶æ”¯æŒæ•°æ®é©±åŠ¨çš„å†³ç­–å’Œè¿è¥ä¼˜åŒ–ã€‚</p>
<p>é™¤äº†æ ¸å¿ƒç»„ä»¶ä¹‹å¤–ï¼ŒELK ç”Ÿæ€ç³»ç»Ÿè¿˜åŒ…æ‹¬å…¶ä»–å·¥å…·å’Œæ’ä»¶ï¼Œç”¨äºæ‰©å±•å’Œå¢å¼ºåŠŸèƒ½ã€‚ä¾‹å¦‚ï¼ŒBeats ç”¨äºè½»é‡çº§æ•°æ®æ”¶é›†ï¼ŒElastic APM ç”¨äºåº”ç”¨æ€§èƒ½ç›‘æ§ï¼ŒElasticsearch SQL ç”¨äºæ‰§è¡Œ SQL æŸ¥è¯¢ç­‰ã€‚</p>
<p>æ€»è€Œè¨€ä¹‹ï¼ŒELK æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å¹³å°ï¼Œç”¨äºé›†ä¸­å­˜å‚¨ã€æœç´¢ã€åˆ†æå’Œå¯è§†åŒ–å„ç§ç±»å‹çš„æ•°æ®ã€‚å®ƒçš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ä½¿å…¶æˆä¸ºå¤„ç†å¤§è§„æ¨¡æ•°æ®å’Œè§£å†³å®æ—¶åˆ†ææŒ‘æˆ˜çš„ç†æƒ³é€‰æ‹©ã€‚</p>
<h3 id="ç™»å½•ä¿¡æ¯">ç™»å½•ä¿¡æ¯</h3>
<p>åœ¨å¯åŠ¨ä¸€ä¸ªé¡¹ç›®ï¼ˆtest-lessonï¼‰ä¹‹åï¼Œèƒ½è·å¾—è´¦å·å¯†ç </p>
<p>username,password<br>
elastic,gUhQRAqAalsPgBFXVxzGwkCV</p>
<h3 id="home-page">Home page</h3>
<p><a href="https://test-lesson-93537f.kb.us-central1.gcp.cloud.es.io:9243/app/integrations/browse">Browse integrations - Integrations - Elastic (es.io)</a></p>
<p>ç«¯å£æ˜¯9243</p>
<p>https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243</p>
<h3 id="æ³¨å†Œ-with-ubuntu">æ³¨å†Œ with ubuntu</h3>
<pre><code class="language-ubuntu">curl --version
</code></pre>
<pre><code class="language-ubuntu">curl -X GET -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/_cat/indices?v'
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516171051.png" alt="" loading="lazy"></figure>
<h3 id="åˆ›å»ºä¸€ä¸ªindex">åˆ›å»ºä¸€ä¸ªindex</h3>
<pre><code>curl -X PUT 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer?pretty'
</code></pre>
<p>ä¸ä¼šæˆåŠŸï¼Œéœ€è¦æ·»åŠ èº«ä»½éªŒè¯ï¼ˆæ€»æ˜¯éœ€è¦å—ï¼Ÿï¼‰</p>
<pre><code class="language-ubuntu">curl -X PUT -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer?pretty'
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516171857.png" alt="" loading="lazy"></figure>
<pre><code class="language-ubuntu">curl -X GET -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/_cat/indices?v'
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516172240.png" alt="" loading="lazy"></figure>
<p>å¯ä»¥çœ‹åˆ°å·²ç»å¤šäº†ä¸€ä¸ªcustomer</p>
<pre><code>curl -X PUT -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer/_doc/1?pretty' -H 'Content-Type:application/json' -d '{\&quot;firstname\&quot;:\&quot;John\&quot;, \&quot;lastname\&quot;:\&quot;Doe\&quot;, \&quot;age\&quot;:22}' 
</code></pre>
<p>ğŸ¤¡ï¼Œä¸éœ€è¦è½¬ä¹‰å­—ç¬¦æ</p>
<pre><code class="language-ubuntu">curl -X PUT -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer/_doc/1?pretty' -H 'Content-Type:application/json' -d '{&quot;firstname&quot;:&quot;John&quot;, &quot;lastname&quot;:&quot;Doe&quot;, &quot;age&quot;:22}'
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516173535.png" alt="" loading="lazy"></figure>
<pre><code class="language-ubuntu">curl -X PUT -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer/_doc/2?pretty' -H 'Content-Type:application/json' -d '{&quot;firstname&quot;:&quot;Anna&quot;, &quot;lastname&quot;:&quot;Conda&quot;, &quot;age&quot;:37}'
</code></pre>
<pre><code class="language-ubuntu">curl -X PUT -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer/_doc/3?pretty' -H 'Content-Type:application/json' -d '{&quot;firstname&quot;:&quot;Bob&quot;, &quot;lastname&quot;:&quot;Dylan&quot;, &quot;age&quot;:37}'
</code></pre>
<p>æ¥ä¸‹æ¥ä½¿ç”¨queryè¯­å¥å°æ£€æŸ¥ä¸€æ‰‹</p>
<pre><code class="language-ubuntu">curl -X GET -u elastic:gUhQRAqAalsPgBFXVxzGwkCV 'https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243/customer/_doc/1?pretty'
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516174431.png" alt="" loading="lazy"></figure>
<p>æˆ–è€…ä½¿ç”¨äº‘ä¸Šï¼ˆæˆ–æ˜¯æœ¬åœ°çš„ï¼‰webç•Œé¢çš„Dev  Tools å‘é€å‘½ä»¤ï¼š</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516174913.png" alt="" loading="lazy"></figure>
<h3 id="å¯è§†åŒ–-in-kibana">å¯è§†åŒ– in kibana</h3>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516180803.png" alt="" loading="lazy"></figure>
<p>åˆ›å»ºä¸€ä¸ªåä¸ºâ€œcustomerâ€çš„index patternï¼Œåœ¨åˆ›å»ºè¾“å…¥åå­—çš„æ—¶å€™ï¼Œä¼šè‡ªåŠ¨åŒ¹é…å·²æœ‰çš„èµ„æºã€‚</p>
<p>å®ç°å››ä¸ªfiler(DSL query)</p>
<ul>
<li>
<p>firstname : Anna</p>
<pre><code class="language-sql">{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;firstname&quot;: &quot;Anna&quot;
    }
  }
}
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516183355.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>firstname : *n(æ‰¾åˆ°ä»»ä½•ä»¥nç»“å°¾çš„)</p>
<pre><code class="language-sql">{
  &quot;wildcard&quot;: {
    &quot;firstname&quot;: &quot;*n&quot;
  }
}
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516183507.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>firstname : *n*</p>
<pre><code class="language-sql">{
  &quot;wildcard&quot;: {
    &quot;firstname&quot;: &quot;*n*&quot;
  }
}
</code></pre>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/image-20230516183852518.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>age &gt; 23</p>
</li>
</ul>
<pre><code class="language-sql">{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;age&quot;: {
        &quot;gt&quot;: 23
      }
    }
  }
}
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516184127.png" alt="" loading="lazy"></figure>
<p>é™¤äº† <code>gt</code>ï¼ŒElasticsearch çš„ range æŸ¥è¯¢è¿˜æ”¯æŒä»¥ä¸‹æ“ä½œç¬¦ï¼š</p>
<ul>
<li><code>lt</code>ï¼šå°äºï¼ˆless thanï¼‰</li>
<li><code>gte</code>ï¼šå¤§äºæˆ–ç­‰äºï¼ˆgreater than or equal toï¼‰</li>
<li><code>lte</code>ï¼šå°äºæˆ–ç­‰äºï¼ˆless than or equal toï¼‰</li>
</ul>
<h3 id="æŸ±çŠ¶å›¾å¯è§†åŒ–ageå’Œcount">æŸ±çŠ¶å›¾å¯è§†åŒ–ï¼ˆageå’Œcountï¼‰</h3>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516210732.png" alt="" loading="lazy"></figure>
<p>save as â€œcustomer per ageâ€ å¹¶åœ¨dashboardä¸Šå±•ç¤ºã€‚</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516211109.png" alt="" loading="lazy"></figure>
<h3 id="python-elastic">Python &amp; Elastic</h3>
<p>ä½¿ç”¨pipå®‰è£…ï¼š</p>
<pre><code class="language-cmd">pip install elasticsearch
</code></pre>
<p>ä»¥kaggleæ•°æ®é›†ä¸ºä¾‹å­è¿›è¡Œè¯•éªŒï¼šï¼ˆhttps://www.kaggle.com/datasets/datasnaek/chessï¼‰</p>
<pre><code class="language-python">from datetime import datetime
import os
from elasticsearch import Elasticsearch,helpers

password = os.environ[&quot;ENV_PASSWORD&quot;]
client = Elasticsearch(hosts=[&quot;https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243&quot;],basic_auth=('elastic',password))  
docs = []
docs.append({&quot;name&quot;:&quot;Bob&quot;,&quot;timestamp&quot;:datetime.utcnow().isoformat()})

helpers.bulk(client,docs,index=&quot;index_fo_python_test&quot;)
</code></pre>
<p>ä¸€å¼€å§‹ç›´æ¥ç»™<code>os.environ[&quot;ENV_PASSWORD&quot;]</code>é‡Œè¾“å…¥äº†æˆ‘çš„å¯†ç ï¼Œä½†è¿™æ˜¯ä¸æ­£ç¡®çš„ï¼Œä¼šæŠ¥é”™key errorï¼Œ<code>password = os.environ[]</code> è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯ä»ç¯å¢ƒå˜é‡ä¸­è·å–ä¸€ä¸ªå€¼ï¼Œå¹¶å°†å…¶èµ‹ç»™å˜é‡ <code>password</code>ã€‚</p>
<p>åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œç¯å¢ƒå˜é‡æ˜¯ä¸€äº›å…¨å±€çš„å€¼ï¼Œç”¨äºå­˜å‚¨é…ç½®ä¿¡æ¯ã€è®¤è¯å‡­æ®ã€è·¯å¾„ç­‰ã€‚é€šè¿‡ä½¿ç”¨ <code>os.environ</code>ï¼Œä½ å¯ä»¥åœ¨ Python è„šæœ¬ä¸­è®¿é—®è¿™äº›ç¯å¢ƒå˜é‡ã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼Œ<code>os.environ</code> æ˜¯ä¸€ä¸ªå­—å…¸å¯¹è±¡ï¼Œå®ƒåŒ…å«äº†å½“å‰ç³»ç»Ÿç¯å¢ƒä¸­æ‰€æœ‰å·²å®šä¹‰çš„ç¯å¢ƒå˜é‡ã€‚ä½ å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡æ¥å­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚å¯†ç ã€API å¯†é’¥ç­‰ï¼‰ï¼Œè€Œä¸éœ€è¦ç›´æ¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç è¿™äº›æ•æ„Ÿä¿¡æ¯ã€‚</p>
<p>æ‰€ä»¥éœ€è¦åœ¨ç¯å¢ƒä¸­è®¾ç½®å…¶å€¼ï¼š</p>
<pre><code class="language-cmd">set ENV_PASSWORD=gUhQRAqAalsPgBFXVxzGwkCV
</code></pre>
<p>å†æ¬¡è¿è¡Œpythonæ–‡ä»¶ï¼Œé€šè¿‡ï¼Œæ¥ä¸‹æ¥å»è¿›è¡Œå¯è§†åŒ–</p>
<p>å»å¾€Stack Managementé¡µé¢ï¼ŒæŸ¥çœ‹å¹¶åˆ›å»ºä¸€ä¸ªdata viewsï¼Œä¸¥æ ¼æŒ‰ç…§pythonä»£ç é‡Œé¢çš„ä¿¡æ¯åˆ›å»ºï¼š</p>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516214519.png" alt="" loading="lazy"></figure>
<p>å›åˆ°discoverï¼Œå¹¶é€‰æ‹©index_fo_python_test</p>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516214844.png" alt="" loading="lazy"></figure>
<h3 id="ä½¿ç”¨pythonè¿›è¡Œå®æ—¶å‘é€">ä½¿ç”¨pythonè¿›è¡Œå®æ—¶å‘é€</h3>
<p>æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹çš„ä»£ç è¿›è¡Œå®æ—¶å‘é€ï¼š</p>
<pre><code class="language-python">import datetime
import random
import time
import os
from elasticsearch import Elasticsearch, helpers

# è¿æ¥ Elasticsearch
password = os.environ[&quot;ENV_PASSWORD&quot;]
es = Elasticsearch(hosts=[&quot;https://test-lesson-93537f.es.us-central1.gcp.cloud.es.io:9243&quot;],basic_auth=('elastic',password))  
# å®šä¹‰å‘é€æ•°æ®çš„å‡½æ•°
def send_data():
    # ç”Ÿæˆéšæœºæ•°æ®
    data = {
        &quot;timestamp&quot;: datetime.datetime.utcnow(),
        &quot;value&quot;: random.randint(1, 100)
    }

    # æ„å»ºç´¢å¼•æ“ä½œ
    action = {
        &quot;_index&quot;: &quot;index_for_realtime_by_python&quot;,
        &quot;_source&quot;: data
    }

    # æ‰¹é‡ç´¢å¼•æ•°æ®
    helpers.bulk(es, [action])

# å‘é€æ•°æ®å¹¶è§‚å¯Ÿä»ªè¡¨ç›˜å˜åŒ–
while True:
    # å‘é€æ•°æ®åˆ° Elasticsearch
    send_data()

    # æš‚åœ5ç§’
    time.sleep(5)

</code></pre>
<p>åœ¨å¹³å°ä¸Šè¿›è¡Œå¯è§†åŒ–è®¾ç½®ï¼ˆåˆ«å¿˜äº†æ–°å»ºä¸€ä¸ªdataviewï¼ŒåŒä¸Šï¼‰</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516221022.png" alt="" loading="lazy"></figure>
<p>åœ¨dashboardä¸Šçœ‹èµ·æ¥è¿™ä¸ªå›¾åƒæ˜¯æ­»çš„ï¼Œä½ éœ€è¦æ‰‹åŠ¨åˆ·æ–°ã€‚è¿™æ—¶å»åˆ°discoveré¡µé¢ï¼šå³ä¸Šè§’è®¾ç½®refresh every 1sï¼ˆæˆ–æ˜¯æ›´çŸ­ï¼‰ï¼Œæ­¤æ—¶å›¾è¡¨å°±å®æ—¶åŠ¨èµ·æ¥åŠ›ï¼</p>
<figure data-type="image" tabindex="17"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/20230516222304.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[å†™åœ¨æœ€å¼€å§‹]]></title>
        <id>https://gagumi.github.io/post/xie-zai-zui-kai-shi/</id>
        <link href="https://gagumi.github.io/post/xie-zai-zui-kai-shi/">
        </link>
        <updated>2023-05-13T06:24:27.000Z</updated>
        <summary type="html"><![CDATA[<p style="font-size:20px;">å·®ä¸å¤šå¾—äº†ğŸ˜…</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3"  loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
]]></summary>
        <content type="html"><![CDATA[<p style="font-size:20px;">å·®ä¸å¤šå¾—äº†ğŸ˜…</p>
<audio controls src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/audio/HOYO-MiX%20_%20Anthony%20Lynch%20-%20%E8%B8%8F%E4%B8%8A%E6%97%85%E9%80%94%20Take%20the%20Journey.flac" type="audio/flac" volume="0.3"  loop>
  å¯¹ä¸èµ·ï¼Œä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ audio å…ƒç´ ã€‚
</audio>
<!-- more -->
<p>å¤©é“é…¬å‹¤ï¼Œå®é™è‡´è¿œï¼Œå¤©çŸ¥é“å“¥ä»¬èƒ½åšæŒå†™è¿™båšå®¢å¤šä¹…æã€‚</p>
<p>ä¸è®ºå¦‚ä½•å…ˆæµ‹è¯•ä¸€ä¸‹PicGoçš„å›¾ç‰‡ã€‚</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Gagumi/MyPicGo/main/img/%E8%B0%A2%E8%8F%B2%E5%B0%94%E5%BE%B7(%CE%BC%E5%85%B5%E8%A3%85).png" alt="æµ‹è¯•å›¾ç‰‡ï¼ˆè°¢è²å°”å¾·å…µè£…ï¼‰" loading="lazy"></figure>
<p>trÃ¨s bienï¼å°±è¿™æ ·å§ï¼Œä»Šå¤©å…ˆåˆ°è¿™å„¿ï¼Œç¡äº†ğŸ˜…</p>
]]></content>
    </entry>
</feed>